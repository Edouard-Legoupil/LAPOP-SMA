---
title: "Authoritarianism index"
author: "Craig Jolley"
date: "October 6, 2015"
output: html_document
---

I'm interested in putting together an index to measure authoritarian attitudes. I think the following indicators are likely to be relevant:

- `d1`: Approval of government critics' right to vote (1=low, 10=high)
- `d2`: Approval of government critics' right to hold peaceful demonstrations
- `d3`: Approval of government critics' right to run for office
- `d4`: Approval of government critics' right to make speeches
- `dem2`: Support for democracy or dictatorship (1=either is OK, 2=democracy, 3=dictatorship)
- `dem11`: Support for mano dura policies (1=iron fist, 2=broad participation)
- `aut1`: Strong leader vs. electoral democracy (1=strong leader, 2=electoral democracy)
- `jc10`: Coup is justified when crime is high (1=yes, 2=no)
- `jc13`: Coup is justified when corruption is high (1=yes, 2=no)
- `jc15a`: President justified in governing without legislature during crisis (1=yes, 2=no)
- `jc16a`: President justified in dissolving Supreme Court of Justice (1=yes, 2=no)
- `ing4`: Democracy better than other forms of government (1=disagree, 7=agree)
- `e5`: Approval of participation in legal demonstrations (1=disapprove, 10=approve)
- `e15`: Approval of blocking roads during protest (1=approve, 10=disapprove)
- `e3`: Approval of groups attempting to overthrow government (1=disapprove, 10=approve)
- `e16`: Approval of vigilante justice (1=disapprove, 10=approve)
- `honjc17`: Justified for Supreme Court to remove the president (1=yes, 2=no)

It's possible that a single index won't capture the effects of all of these, and they might not vary in the ways I expect. This is an experiment, and I'll show how to check whether my assumptions are justified.

To start off, we'll load the necessary packages:

```{r, message=FALSE}
library(ggplot2)
#install.packages("mice") # if you don't have it already
library(mice)
library(plyr) # nice for re-formatting data
#install.packages("GGally") # if you don't have it already
library(GGally) # for plot matrices
```

We'll load the 2014 Honduras data set, and construct a data frame containing the columns we want.

```{r}
lapop.2014.HND <- read.csv('2014-HND.csv')
my_data <- lapop.2014.HND[,c('d1','d2','d3','d4','dem2','dem11','aut1','jc13',
                             'jc10','jc15a','jc16a','ing4','e5','e15','e3','e16','honjc17')]
#dem2 has sort of an odd scale -- switch 1 and 2
my_data$dem2[my_data$dem2==1] <- 100
my_data$dem2[my_data$dem2==2] <- 1
my_data$dem2[my_data$dem2==100] <- 2
is.na(my_data[my_data>16]) <- TRUE
```

What does PCA looks like with the complete data?

```{r}
my_complete <- na.omit(my_data)
pr_complete <- prcomp(my_complete,center=TRUE,scale=FALSE)
plot(pr_complete)
summary(pr_complete)
```

This isn't super-concentrated in the first component (34%), which isn't as encouraging as the wealth index was -- this is going to be a lot more complicated. I think what I'll do is build the composite index, then go back and see which variables are well-predicted by this index. If any don't correlate significantly, I'll drop them from the analysis.

```{r}
my_imp <- mice(my_data,printFlag = F) 
my_imp
```

So people were a little reluctant to talk about whether they like dictatorships (`aut2`) or when a coup or something similar might be justified (`jc10`,`jc13`,`jc15a`,`jc16a`), and a lot more clear on what they think of protests (`e3`,`e5`,`e15`) and vigilante justice (`e16`). 

Moving on to the PCA:

```{r}
pr <- lapply(1:5,function(x) prcomp(complete(my_imp,x),scale=FALSE,center=TRUE))
plot(pr[[1]])
summary(pr[[1]])
```

PCA results look very similar to what we saw without imputation, which is good.

```{r}
pc1 <- pr[[1]]$x[,1]
pc2 <- pr[[1]]$x[,2]
qplot(pc1,pc2)
```

The scatterplot isn't nearly as clean-looking as it was with the wealth index, probably because we have a lot more variables that take on more than two values now. No obvious clustering.

```{r, fig.width=10, fig.height=10}
all_pc1 <- data.frame(llply(1:5, function(i) pr[[i]]$x[,1]))
names(all_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(all_pc1) + theme_classic()
```

All of our imputations are really well-correlated, and the distributions of PC1 don't look crazy.

```{r}
all_pc1$avg <- rowMeans(all_pc1)
quantile(all_pc1$avg)
colMeans(my_data[all_pc1$avg < quantile(all_pc1$avg)[2],],na.rm=TRUE)
colMeans(my_data[all_pc1$avg > quantile(all_pc1$avg)[4],],na.rm=TRUE)
```

What are we seeing here? Compared to the lowest quantile, the highest quantile of our proposed index has:
- Much higher values for `d1` (they approve of government critics voting)
- Much higher values for `d2` (they approve of government critics demonstrating)
- Much higher values for `d3` (they approve of government critics running for office)
- Much higher values for `d4` (they approve of government critics making speeches)
- About the same values for `dem2` (they either like democracy or don't care)
- About the same values for `dem11` (middle-of-the road on mano dura)
- About the same values for `aut1` (preferring democracy)
- Similar values for `jc10`,`jc13`,`jc15a`,`jc15a`,`jc16a` (most don't approve of coups)
- Somewhat higher values for `ing4` (democracy better than other forms)
- Much higher values for `e3`,`e5`,`e15`,`e16` (approval of protests)
- Very similar values for `honjc17` (split on Supreme Courrt removing the president)

In general, it looks like PC1 does a good job of dividing people up based on their sympathy for government critics, but not anything else. This could be because people who sympathize with government critics don't all do so for the same reasons! 

Let's normalize and average PC1:

```{r}
all_pc1$norm <- scale(all_pc1$avg)
```

You can modify the code above to check this on your own, but PC2 through PC17 also have extremely high correlations among the five imputed datasets. It seems that the missing values could be imputed with high enough confidence that the PCA calculations are all really similar to each other, but that nothing beyond PC1 seems to have a really unique interpretation.

I've got some ideas about which variables could be dropped from our index, but we can check this by seeing how each contributes to the index score:

```{r,warning=FALSE}
predict_data <- data.frame(d1=c(1,10),d2=c(1,10),d3=c(1,10),d4=c(1,10),
                           dem2=c(1,3),dem11=c(1,2),aut1=c(1,2),jc13=c(1,2),
                           jc10=c(1,2),jc15a=c(1,2),jc16a=c(1,2),ing4=c(1,7),
                           e5=c(1,10),e15=c(1,10),e3=c(1,10),e16=c(1,10),
                           honjc17=c(1,2))
minmax <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data)[,1]))
minmax <- (minmax-mean(all_pc1$avg)) / sd(all_pc1$avg)

predict_data2 <- data.frame(diag(17)+1)
names(predict_data2) <- names(my_data)
scores <- rowMeans(sapply(1:5, function(i) predict(pr[[i]],predict_data2)[,1]))
scores <- (scores-mean(all_pc1$avg)) / sd(all_pc1$avg)
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))
ggplot(diff,aes(x=n,y=d)) +
  geom_bar(stat='identity',fill='skyblue') +
  coord_flip() +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank())
```

This isn't too surprising -- the indicators that we saw being strongly influenced by our composite index are the same that have a strong influence on it. Many appear to have no effect at all. 

We can be more rigorous about this by calculating p-values. We'll have to do this differently for the indicators that take on several values (a scale of 1-7 or 1-10) than for the ones that only take on two. 

```{r}
lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}
sapply(c('d1','d2','d3','d4','e3','e5','e15','e16','ing4'),
       function(x) lmp(lm(all_pc1$norm ~ my_data[,x])))
```

All are extremely significant except `ing4`; let's visualize that one and see what's going on:

```{r}
ing4 <- data.frame(q=my_data$ing4,w=all_pc1$norm)
ing4 <- na.omit(ing4)
my_lm <- lm(data=ing4, q ~ w)
summary(my_lm)
ggplot(ing4,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('ing4') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

Now let's look at the binary indicators. `dem2` is kind of tricky because it can take on three values -- I'll turn this into two different binary indicators for the two extreme answers.

```{r}
log_data <- my_data[,c('aut1','dem11','honjc17','jc10','jc13','jc15a','jc16a')]
log_data <- log_data - 1 #convert to 0-1 scale
log_data$dem2_1 <- my_data$dem2<2
log_data$dem2_3 <- my_data$dem2>2
p_vals <- sapply(log_data, function(x) coef(summary(glm(x ~ all_pc1$norm,family=binomial(logit))))[2,4])
p_vals
```

The only ones that look like they *might* be significant are `aut1` and `jc13`.

```{r}
aut1 <- data.frame(r=my_data$aut1-1,x=all_pc1$norm)
aut1 <- na.omit(aut1)
ggplot(aut1,aes(x=x,y=r)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0.1,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('aut1') +
  xlab('Composite index') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 

```

Not sure I believe this one.

```{r}
jc13 <- data.frame(r=my_data$jc13-1,x=all_pc1$norm)
jc13 <- na.omit(jc13)
ggplot(jc13,aes(x=x,y=r)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0.1,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('aut1') +
  xlab('Composite index') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
```

Same story here. My inclination here is to create a new index containing only the variables that correlate strongly with this composite index.

```{r, fig.width=10, fig.height=10}}
my_data2 <- lapop.2014.HND[,c('d1','d2','d3','d4','e3','e5','e15','e16')]
is.na(my_data2[my_data2>16]) <- TRUE
my_imp2 <- mice(my_data2,printFlag = F) 
pr2 <- lapply(1:5,function(x) prcomp(complete(my_imp2,x),scale=FALSE,center=TRUE))
plot(pr2[[1]])
summary(pr2[[1]])
```

We're still only seeing 36% of the variance in that first component, so things haven't changed a lot so far.

```{r}
critics_tol <- data.frame(llply(1:5, function(i) pr2[[i]]$x[,1]))
names(critics_tol) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(critics_tol) + theme_classic()
```

So far, so good.

```{r}
critics_tol$avg <- rowMeans(critics_tol)
critics_tol$norm <- scale(critics_tol$avg)
colMeans(my_data2[critics_tol$norm < quantile(critics_tol$norm)[2],],na.rm=TRUE)
colMeans(my_data2[critics_tol$norm > quantile(critics_tol$norm)[4],],na.rm=TRUE)
```

Values for all of the indicators go up significantly as the composite index increases, as we'd expect.

```{r}
sapply(c('d1','d2','d3','d4','e3','e5','e15','e16'),
       function(x) lmp(lm(critics_tol$norm ~ my_data[,x])))
```

We'll visualize `e16` (approval of vigilante justice); modify the code below if you want to look at the others:

```{r}
e16 <- data.frame(q=my_data$e16,w=critics_tol$norm)
e16 <- na.omit(e16)
my_lm <- lm(data=e16, q ~ w)
summary(my_lm)
ggplot(e16,aes(x=w,y=q)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('e16') +
  xlab('Composite index') +
  theme(text=element_text(size=20)) 
```

None of the correlations are perfect, but all are significant. 

Now, can we build another composite out of (some of) the remaining indicators? Let's leave out `ing4`, since that correlated somewhat with the last one, and we don't want it to dominate here.

```{r}
my_data3 <- lapop.2014.HND[,c('dem2','dem11','aut1','jc13','jc10','jc15a',
                              'jc16a','honjc17')]
#dem2 has sort of an odd scale -- switch 1 and 2
my_data3$dem2[my_data3$dem2==1] <- 100
my_data3$dem2[my_data3$dem2==2] <- 1
my_data3$dem2[my_data3$dem2==100] <- 2
is.na(my_data3[my_data3>16]) <- TRUE
my_imp3 <- mice(my_data3,printFlag = F) 
pr3 <- lapply(1:5,function(x) prcomp(complete(my_imp3,x),scale=FALSE,center=TRUE))
plot(pr3[[1]])
summary(pr3[[1]])
```

So our first component contains 33.7% of the variance, which is about like before. Maybe this is going to work.

```{r}
new_pc1 <- data.frame(llply(1:5, function(i) pr3[[i]]$x[,1]))
names(new_pc1) <- c('imp1','imp2','imp3','imp4','imp5')
ggpairs(new_pc1) + theme_classic()
```

Correlations are good, but the distributions are sort of weird -- skewed toward high values. What does this mean?

```{r}
new_pc1$avg <- rowMeans(new_pc1)
new_pc1$norm <- scale(new_pc1$avg)
quantile(new_pc1$norm)
colMeans(my_data3[new_pc1$norm < quantile(new_pc1$norm)[2],],na.rm=TRUE)
colMeans(my_data3[new_pc1$norm > quantile(new_pc1$norm)[4],],na.rm=TRUE)
```

So the people near the top of the distribution answered 2 to almost everything, except `dem2`, where they answered 1. They disapprove of coups and they like democracy. Thank goodness it's skewed high. The people near the bottom were more ambivalent on all these things. Let's reverse this, so that higher values mean more authoritarianism.

```{r,warning=FALSE}
predict_data <- data.frame(dem2=c(1,3),dem11=c(1,2),aut1=c(1,2),jc13=c(1,2),
                           jc10=c(1,2),jc15a=c(1,2),jc16a=c(1,2),honjc17=c(1,2))
minmax <- rowMeans(sapply(1:5, function(i) predict(pr3[[i]],predict_data)[,1]))
minmax <- (minmax-mean(new_pc1$avg)) / sd(new_pc1$avg)
predict_data2 <- data.frame(diag(8)+1)
names(predict_data2) <- names(my_data3)
scores <- rowMeans(sapply(1:5, function(i) predict(pr3[[i]],predict_data2)[,1]))
scores <- (scores-mean(new_pc1$avg)) / sd(new_pc1$avg)
diff <- data.frame(d=(scores - minmax[1]),n=names(predict_data))
ggplot(diff,aes(x=n,y=d)) +
  geom_bar(stat='identity',fill='skyblue') +
  coord_flip() +
  theme_classic() +
  theme(text=element_text(size=20),
        axis.title.y=element_blank(),
        axis.title.x=element_blank())
```

`dem2` has a stronger effect than the others and an opposite sign -- larger values mean more authoritarian attitudes, while in other cases larger values mean rejection of coups, etc.

```{r}
log_data <- my_data3[,c('aut1','dem11','honjc17','jc10','jc13','jc15a','jc16a')]
log_data <- log_data - 1 #convert to 0-1 scale
p_vals <- sapply(log_data, function(x) coef(summary(glm(x ~ new_pc1$norm,family=binomial(logit))))[2,4])
p_vals
```


This time, all of our logistic regressions are significant. Let's look at `aut1` (1=prefers strong leader, 2=prefers electoral democracy)

```{r}
aut1 <- data.frame(r=my_data$aut1-1,x=new_pc1$norm)
aut1 <- na.omit(aut1)
ggplot(aut1,aes(x=x,y=r)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('aut1') +
  xlab('New composite index') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
```

So most people prefer electoral democracy (`aut1`=2), but those who don't are unusually likely to have low values of this composite score. The three clear groupings make me suspicious that this will correlate very strongly with `dem2`, which takes on three values.

```{r}
dem2 <- data.frame(r=my_data$dem2,x=new_pc1$norm)
dem2 <- na.omit(dem2)
my_lm <- lm(data=dem2, r ~ x)
summary(my_lm)
ggplot(dem2,aes(x=x,y=r)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0,0.1)) +
  theme_classic() +
  geom_smooth(method='lm',size=2,color='royalblue') +
  annotate('text',label=paste("R-sq:",round(summary(my_lm)$r.squared,2)),  
           size=10,x=-0.5,y=2.5,hjust=0,vjust=0,color='royalblue') +
  ylab('dem2') +
  xlab('New composite index') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
```

So this index is really dominated by `dem2`. Is it better than just using `dem2` without going to all of this work?

```{r}
# Saw this already - p-values for composite index
sapply(log_data, function(x) coef(summary(glm(x ~ new_pc1$norm,family=binomial(logit))))[2,4])
sapply(log_data, function(x) coef(summary(glm(x ~ my_data3$dem2,family=binomial(logit))))[2,4])
```

While `dem2` is pretty good at predicting a lot of these variables, our composite index does better, with lower p-values all around. When we're presenting final results, it might be good to see if we can do it using `dem2` instead of our index, because it will be easier for people to understand.

Finally, with two composite indices we can see why they didn't line up very well at first:

```{r}
both <- data.frame(x=critics_tol$norm,y=new_pc1$norm)
my_lm <- lm(y~x,data=both)
summary(my_lm)
ggplot(both,aes(x=x,y=y)) +
  geom_point(color='tomato3',size=5,alpha=0.2) +
  theme_classic() +
  ylab('Authoritarianism') +
  xlab("Tolerance of gov't critics") +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
```

So tolerance of government critics spans a pretty wide range, while relatively few people have strongly authoritarian attitudes. It's intriguing that they don't seem to correlate much.

Since what we're ultimately interested in here is violent crime, let's see whether either of these can predict `vic1ext`.

```{r}
vic1ext <- data.frame(ind1=critics_tol$norm,ind2=new_pc1$norm,v=2-lapop.2014.HND$vic1ext)
is.na(vic1ext[vic1ext==-888886]) <- TRUE
vic1ext <- na.omit(vic1ext)
ggplot(vic1ext,aes(x=ind1,y=v)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('vic1ext') +
  xlab('Tolerance of government critics') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
my_glm <- glm(data=vic1ext, v ~ ind1, family=binomial(logit))
summary(my_glm)
```

So tolerance of government critics has only weak influence (p = 0.095). What about our authoritarianism index?

```{r}
ggplot(vic1ext,aes(x=ind2,y=v)) +
  geom_jitter(color='tomato3',size=5,alpha=0.2,position=position_jitter(0,0.1)) +
  theme_classic() +
  stat_smooth(method="glm", family="binomial",size=2,color='royalblue',se=FALSE) +
  ylab('vic1ext') +
  xlab('Authoritarianism') +
  theme(text=element_text(size=20),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) 
my_glm <- glm(data=vic1ext, v ~ ind2, family=binomial(logit))
summary(my_glm)
```

This time p = 0.00003 -- we're really on to something now. While most people aren't victims and most people don't have authoritarian attitudes, those two things go together more often than you would expect if they were completely independent. 
